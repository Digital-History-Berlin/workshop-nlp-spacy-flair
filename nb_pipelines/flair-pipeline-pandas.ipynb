{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9cfeae6-f39e-4f44-8775-20992530d63d",
   "metadata": {},
   "source": [
    "# Flair Pipeline mit pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3beeadd-3b85-4850-b5e3-ccfbc0647b09",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f890159d-350b-4a7c-86a1-70d9dd16871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from flair.tokenization import SegtokSentenceSplitter\n",
    "\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d03248b-703a-477a-9825-e706f2d3a32b",
   "metadata": {},
   "source": [
    "## Laden der Daten\n",
    "\n",
    "Die Daten, mit denen wir arbeiten, ist ein Korpus der die Reden der Bundesregierung seit Anfang der 1980er-Jahre bis 2017 umfasst.\n",
    "\n",
    "Die Daten sind dem Projekt [German Political Speeches Corpus and Visualization](https://politische-reden.eu/) entnommen.\n",
    "\n",
    "Als zip-Datei können die Daten auch hier heruntergeladen werden: https://zenodo.org/record/3611246\n",
    "\n",
    "Es handelt sich dabei um die Datei Bundesregierung.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c089e364-69c0-4918-af8c-1d8d0205abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link ist bis zum 12.3.2022 verfügbar\n",
    "url = 'https://box.hu-berlin.de/f/a2f4accf1cb1477bb505/?dl=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52751638-798d-4b78-91ce-043e7c9d63f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_xml(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29ca819f-4d48-43e5-86e3-dc497c694ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change dtype to datetime\n",
    "df.loc[:, 'datum'] = pd.to_datetime(df.loc[:, 'datum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d33faa24-1519-44cd-8c2e-d5e15a28840b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2983 entries, 0 to 2982\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   person      2983 non-null   object        \n",
      " 1   titel       2982 non-null   object        \n",
      " 2   datum       2983 non-null   datetime64[ns]\n",
      " 3   untertitel  2088 non-null   object        \n",
      " 4   url         2983 non-null   object        \n",
      " 5   anrede      1447 non-null   object        \n",
      " 6   rohtext     2983 non-null   object        \n",
      " 7   ort         690 non-null    object        \n",
      "dtypes: datetime64[ns](1), object(7)\n",
      "memory usage: 186.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa96f2-8f4c-448d-929c-3a63bd66b4c5",
   "metadata": {},
   "source": [
    "### Funktion zum Erstellen des Sentence-Objekts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65034fd9-fe8c-41da-9c0d-22f20d302a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_object(text):\n",
    "    '''\n",
    "    Creates a Flair Sentence-Object.\n",
    "    INPUT: string\n",
    "    RETURN: flair.data.Sentence\n",
    "    '''      \n",
    "        \n",
    "    return Sentence(text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "303fc697-dc54-44b4-9ea8-cf29821d38b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df.loc[:, 'sentence_object'] = df.loc[:, 'rohtext'].apply(lambda text: create_sentence_object(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2744e3ac-b18a-475b-8bdd-ffa19283649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speichern der Datei\n",
    "# Größe der Datei 636 MB\n",
    "\n",
    "# df.to_pickle('../data/flair-reden-bundesregierung.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78294499-91f1-4f45-91ca-c909e54a395e",
   "metadata": {},
   "source": [
    "## Tokenisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f7adde9-e9eb-4321-b5e6-7e46dd550f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e09f144-e75c-4d8e-95f0-af8f5a9b118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    '''\n",
    "    Tokenizes text using Sentence-Object\n",
    "    INPUT: Sentence-Object\n",
    "    RETURN: list with tokens\n",
    "    '''    \n",
    "    \n",
    "    return [ token for token in sentence if str(token) not in string.punctuation ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26e83928-8ed4-4928-b1b8-bf09083e3a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df.loc[:, 'tokens'] = df.loc[:, 'sentence_object'].apply(lambda sentence: tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38c0feb5-ab8b-4a4a-8e4f-c00f9f1e66c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'ntokens'] = df.loc[:, 'tokens'].apply(lambda tokens: len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e5f6994-7a7e-46df-a348-7b93337fb586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     2983.000000\n",
       "mean      2190.128059\n",
       "std       1458.956105\n",
       "min          5.000000\n",
       "25%       1093.000000\n",
       "50%       1803.000000\n",
       "75%       2934.000000\n",
       "max      12217.000000\n",
       "Name: ntokens, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, 'ntokens'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d20f1861-82bb-471b-b529-b10012fee938",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_token = df.loc[0, 'tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4a7f170-f8fe-475a-b684-0bec9cb093f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flair.data.Token"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_token[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11e5ea4-0718-4447-952d-08ea7eba2889",
   "metadata": {},
   "source": [
    "## Lemmatisierung\n",
    "\n",
    "Derzeit noch nicht in Flair implementiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f467d-76e2-4a12-a8a8-ef533a671ad0",
   "metadata": {},
   "source": [
    "## NER\n",
    "\n",
    "NER und POS-Tagging sind im Vergleich zu SpaCy sehr, sehr langsam. Eine GPU würde dies zwar beschleunigen, wäre dennoch deutlich langsamer.\n",
    "\n",
    "Dafür wäre allerdings Accuracy bei der NER mit Flair um mehr als 10 % höher.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b37fb3-dab6-413a-a812-89ec96aa7114",
   "metadata": {},
   "source": [
    "### Speed Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa9cefe2-cdfb-4334-9d43-3a87a9a0b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rohtext = df.loc[0,'rohtext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "463500a9-c0c8-455d-b13d-7fede8e0423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_rohtext = Sentence(rohtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51c1b002-afac-49c7-a6b2-9334b1c0478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-23 16:02:51,363 --------------------------------------------------------------------------------\n",
      "2022-02-23 16:02:51,366 The model key 'de-ner' now maps to 'https://huggingface.co/flair/ner-german' on the HuggingFace ModelHub\n",
      "2022-02-23 16:02:51,367  - The most current version of the model is automatically downloaded from there.\n",
      "2022-02-23 16:02:51,367  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/de-ner/de-ner-conll03-v0.4.pt)\n",
      "2022-02-23 16:02:51,368 --------------------------------------------------------------------------------\n",
      "2022-02-23 16:02:51,897 loading file C:\\Users\\nitra\\.flair\\models\\ner-german\\a125be40445295f7e94d0afdb742cc9ac40ec4e93259dc30f35220ffad9bf1f6.f46c4c5cfa5e34baa838983373e30051cd1cf1e933499408a49e451e784b0a11\n"
     ]
    }
   ],
   "source": [
    "tagger = SequenceTagger.load('de-ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c4d630b-b50c-4554-80f9-d4a38d4d96e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Das NER-Tagging ist sehr langsam!\n",
    "# etwa 45 s für 2241 tokens\n",
    "\n",
    "tagger.predict(sentence_rohtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8abdbb6e-66ed-4f20-b4e5-a001877ce3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2241"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_rohtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39c5b7d5-5253-4937-be0d-ef45a4b2e9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6533152"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, 'ntokens'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1348fb12-bf37-40bb-a743-68c0f475b186",
   "metadata": {},
   "source": [
    "### Berechnungen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b49490-e696-460d-b232-edbe01334e2c",
   "metadata": {},
   "source": [
    "https://spacy.io/usage/facts-figures#benchmarks-speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4799f2-4a78-479f-bb10-256fa78eb402",
   "metadata": {},
   "source": [
    "Durchschnitt der Textlänge: 2190 Tokens\n",
    "\n",
    "Dauer für 2241 Tokens 45 s\n",
    "\n",
    "bei 2983 Dokument macht das ungefähr 37 Stunden!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3703d1e5-3665-4f34-bcaa-aa081a43f0b4",
   "metadata": {},
   "source": [
    "## andere Berechnung aus SpaCy im Vergleich:\n",
    "\n",
    "### Flair\t\n",
    "\n",
    "pos(-fast) & ner(-fast)\n",
    "\n",
    "mit CPU Words per second 323\t\n",
    "\n",
    "dann ergeben sich 5,5 Stunden Laufzeit\n",
    "\n",
    "\n",
    "mit GPU Words per second 1.184\n",
    "\n",
    "dann ergäbe sich eine Laufzeit von 1,5 Stunden\n",
    "\n",
    "allerdings bezieht sich das hier auf das englische ner-fast-Model, hier ist das normale deutsche Modell genutzt\n",
    "\n",
    "### Spacy\n",
    "\n",
    "Spacy benötigt für die Erstellung des Doc-Objekts 11 min 27 s, was genau mit der Speed Comparison übereinstimmt.\n",
    "\n",
    "https://towardsdatascience.com/why-we-switched-from-spacy-to-flair-to-anonymize-french-legal-cases-e7588566825f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9da0bb2d-6c7d-4a79-a6f6-6543c748c90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Das Filtern nach den einzelnen Entities ist dann wiederum recht schnell.\n",
    "\n",
    "list_per = [ token.text for token in sentence_rohtext if str(token.get_tag('ner')).split(' ')[0][-3:] == 'PER' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25cde5e2-3c36-4b24-b442-da512f88de13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hildegard',\n",
       " 'Knef',\n",
       " 'Billy',\n",
       " 'Wilder',\n",
       " 'Audrey',\n",
       " 'Hepburn',\n",
       " 'Robert',\n",
       " 'de',\n",
       " 'Niro',\n",
       " 'Ernst',\n",
       " 'Greta',\n",
       " 'Garbo',\n",
       " 'Ninotschka',\n",
       " 'Achternbusch',\n",
       " 'Dieter',\n",
       " 'Kosslick',\n",
       " 'Krzysztof',\n",
       " 'Kieslowski',\n",
       " 'Tom',\n",
       " 'Tykwer']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_per"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a831608-f436-4656-aafe-739a54aefdda",
   "metadata": {},
   "source": [
    "### vorbereiteter Code für NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26cb32df-3514-4051-b0cd-a92b62a4ad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_named_entities(sentence, tagger, entity):\n",
    "    '''\n",
    "    Extracts named entities from Sentence-Object.\n",
    "    INPUT: Sentence-Object\n",
    "    RETURN: List with entities    \n",
    "    '''    \n",
    "    tagger.predict(sentence)\n",
    "        \n",
    "    return [ token.text for token in sentence if str(token.get_tag('de-ner')).split(' ')[0][-3:] == entity ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f69854-f373-4429-a454-2949eff0711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "entities = ['PER', 'ORG', 'LOC']\n",
    "tagger = SequenceTagger.load('de-ner')\n",
    "\n",
    "for entity in entities:\n",
    "    df.loc[:, entity] = df.loc[:, 'rohtext'].apply(lambda text: extract_named_entities(text, tagger, entity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56298e8c-35cb-4b11-93c8-f92a2de7edd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
